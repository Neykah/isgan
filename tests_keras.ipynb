{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using matplotlib backend: Qt5Agg\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "from keras import backend as K\n",
    "\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, Activation, Flatten, Reshape\n",
    "from keras.layers import Conv2D, Conv2DTranspose, UpSampling2D, Input, MaxPooling2D, AveragePooling2D\n",
    "from keras.layers import LeakyReLU, Dropout\n",
    "from keras.layers import BatchNormalization\n",
    "import keras.layers\n",
    "from keras.optimizers import RMSprop\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 32, 256, 256)      320       \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 32, 256, 256)      1024      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_1 (LeakyReLU)    (None, 32, 256, 256)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 64, 256, 256)      18496     \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 64, 256, 256)      1024      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_2 (LeakyReLU)    (None, 64, 256, 256)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 128, 256, 256)     73856     \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 128, 256, 256)     1024      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_3 (LeakyReLU)    (None, 128, 256, 256)     0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 64, 256, 256)      73792     \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 64, 256, 256)      1024      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_4 (LeakyReLU)    (None, 64, 256, 256)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 32, 256, 256)      18464     \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 32, 256, 256)      1024      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_5 (LeakyReLU)    (None, 32, 256, 256)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 1, 256, 256)       33        \n",
      "=================================================================\n",
      "Total params: 190,081\n",
      "Trainable params: 187,521\n",
      "Non-trainable params: 2,560\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "decoder = Sequential()\n",
    "depth = 32\n",
    "dropout = 0.4\n",
    "input_shape = (1, 256, 256)\n",
    "decoder.add(Conv2D(depth, 3, input_shape=input_shape, padding='same'))\n",
    "decoder.add(BatchNormalization(momentum=0.9))\n",
    "decoder.add(LeakyReLU(alpha=0.2))\n",
    "\n",
    "decoder.add(Conv2D(depth*2, 3, padding='same'))\n",
    "decoder.add(BatchNormalization(momentum=0.9))\n",
    "decoder.add(LeakyReLU(alpha=0.2))\n",
    "\n",
    "decoder.add(Conv2D(depth*4, 3, padding='same'))\n",
    "decoder.add(BatchNormalization(momentum=0.9))\n",
    "decoder.add(LeakyReLU(alpha=0.2))\n",
    "\n",
    "decoder.add(Conv2D(depth*2, 3, padding='same'))\n",
    "decoder.add(BatchNormalization(momentum=0.9))\n",
    "decoder.add(LeakyReLU(alpha=0.2))\n",
    "\n",
    "decoder.add(Conv2D(depth, 3, padding='same'))\n",
    "decoder.add(BatchNormalization(momentum=0.9))\n",
    "decoder.add(LeakyReLU(alpha=0.2))\n",
    "\n",
    "decoder.add(Conv2D(1, 1, padding='same', activation='sigmoid'))\n",
    "\n",
    "decoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def InceptionBlock(filters_in, filters_out):\n",
    "    input_layer = Input(shape=(filters_in, 256, 256))\n",
    "    tower_filters = int(filters_out / 4)\n",
    "\n",
    "    tower_1 = Conv2D(tower_filters, 1, padding='same', activation='relu')(input_layer)\n",
    "\n",
    "    tower_2 = Conv2D(tower_filters, 1, padding='same', activation='relu')(input_layer)\n",
    "    tower_2 = Conv2D(tower_filters, 3, padding='same', activation='relu')(tower_2)\n",
    "\n",
    "    tower_3 = Conv2D(tower_filters, 1, padding='same', activation='relu')(input_layer)\n",
    "    tower_3 = Conv2D(tower_filters, 5, padding='same', activation='relu')(tower_3)\n",
    "\n",
    "    tower_4 = MaxPooling2D(tower_filters, padding='same', strides=(1, 1))(input_layer)\n",
    "    tower_4 = Conv2D(tower_filters, 1, padding='same', activation='relu')(tower_4)\n",
    "\n",
    "    concat = keras.layers.concatenate([tower_1, tower_2, tower_3, tower_4], axis=1)\n",
    "\n",
    "    res_link = Conv2D(filters_out, 1, padding='same', activation='relu')(input_layer)\n",
    "\n",
    "    output = keras.layers.add([concat, res_link])\n",
    "    output = Activation('relu')(output)\n",
    "\n",
    "    model_output = Model([input_layer], output)\n",
    "    return model_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_7 (Conv2D)            (None, 16, 256, 256)      304       \n",
      "_________________________________________________________________\n",
      "batch_normalization_6 (Batch (None, 16, 256, 256)      1024      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_6 (LeakyReLU)    (None, 16, 256, 256)      0         \n",
      "_________________________________________________________________\n",
      "model_1 (Model)              (None, 32, 256, 256)      3280      \n",
      "_________________________________________________________________\n",
      "model_2 (Model)              (None, 64, 256, 256)      12960     \n",
      "_________________________________________________________________\n",
      "model_3 (Model)              (None, 128, 256, 256)     51520     \n",
      "_________________________________________________________________\n",
      "model_4 (Model)              (None, 256, 256, 256)     205440    \n",
      "_________________________________________________________________\n",
      "model_5 (Model)              (None, 128, 256, 256)     100672    \n",
      "_________________________________________________________________\n",
      "model_6 (Model)              (None, 64, 256, 256)      25248     \n",
      "_________________________________________________________________\n",
      "model_7 (Model)              (None, 32, 256, 256)      6352      \n",
      "_________________________________________________________________\n",
      "conv2d_57 (Conv2D)           (None, 16, 256, 256)      4624      \n",
      "_________________________________________________________________\n",
      "batch_normalization_7 (Batch (None, 16, 256, 256)      1024      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_7 (LeakyReLU)    (None, 16, 256, 256)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_58 (Conv2D)           (None, 1, 256, 256)       17        \n",
      "=================================================================\n",
      "Total params: 412,465\n",
      "Trainable params: 411,441\n",
      "Non-trainable params: 1,024\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "encoder = Sequential()\n",
    "input_shape = (2, 256, 256)\n",
    "\n",
    "encoder.add(Conv2D(16, 3, input_shape=input_shape, padding='same'))\n",
    "encoder.add(BatchNormalization(momentum=0.9))\n",
    "encoder.add(LeakyReLU(alpha=0.2))\n",
    "\n",
    "encoder.add(InceptionBlock(16, 32))    # Layer 2\n",
    "encoder.add(InceptionBlock(32, 64))    # Layer 3\n",
    "encoder.add(InceptionBlock(64, 128))   # Layer 4\n",
    "encoder.add(InceptionBlock(128, 256))  # Layer 5\n",
    "encoder.add(InceptionBlock(256, 128))  # Layer 6\n",
    "encoder.add(InceptionBlock(128, 64))   # Layer 7\n",
    "encoder.add(InceptionBlock(64, 32))    # Layer 8\n",
    "\n",
    "encoder.add(Conv2D(16, 3, padding='same')) # Layer 9\n",
    "encoder.add(BatchNormalization(momentum=0.9))\n",
    "encoder.add(LeakyReLU(alpha=0.2))\n",
    "\n",
    "encoder.add(Conv2D(1, 1, padding='same', activation='tanh')) # Output\n",
    "encoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_59 (Conv2D)           (None, 8, 256, 256)       224       \n",
      "_________________________________________________________________\n",
      "batch_normalization_8 (Batch (None, 8, 256, 256)       1024      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_8 (LeakyReLU)    (None, 8, 256, 256)       0         \n",
      "_________________________________________________________________\n",
      "average_pooling2d_1 (Average (None, 8, 128, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_60 (Conv2D)           (None, 16, 128, 128)      1168      \n",
      "_________________________________________________________________\n",
      "batch_normalization_9 (Batch (None, 16, 128, 128)      512       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_9 (LeakyReLU)    (None, 16, 128, 128)      0         \n",
      "_________________________________________________________________\n",
      "average_pooling2d_2 (Average (None, 16, 64, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_61 (Conv2D)           (None, 32, 64, 64)        544       \n",
      "_________________________________________________________________\n",
      "batch_normalization_10 (Batc (None, 32, 64, 64)        256       \n",
      "_________________________________________________________________\n",
      "average_pooling2d_3 (Average (None, 32, 32, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_62 (Conv2D)           (None, 64, 32, 32)        2112      \n",
      "_________________________________________________________________\n",
      "batch_normalization_11 (Batc (None, 64, 32, 32)        128       \n",
      "_________________________________________________________________\n",
      "average_pooling2d_4 (Average (None, 64, 16, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_63 (Conv2D)           (None, 128, 16, 16)       73856     \n",
      "_________________________________________________________________\n",
      "batch_normalization_12 (Batc (None, 128, 16, 16)       64        \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_10 (LeakyReLU)   (None, 128, 16, 16)       0         \n",
      "_________________________________________________________________\n",
      "average_pooling2d_5 (Average (None, 128, 8, 8)         0         \n",
      "_________________________________________________________________\n",
      "spatial_pyramid_pooling_1 (S (None, 2688)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 128)               344192    \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 2)                 258       \n",
      "=================================================================\n",
      "Total params: 424,338\n",
      "Trainable params: 423,346\n",
      "Non-trainable params: 992\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from SpatialPyramidPooling import SpatialPyramidPooling\n",
    "\n",
    "discriminator = Sequential()\n",
    "input_shape = (3, 256, 256)\n",
    "\n",
    "discriminator.add(Conv2D(8, 3, padding='same', input_shape=input_shape))\n",
    "discriminator.add(BatchNormalization(momentum=0.9))\n",
    "discriminator.add(LeakyReLU(alpha=0.2))\n",
    "discriminator.add(AveragePooling2D(pool_size=5, strides=2, padding='same'))\n",
    "\n",
    "discriminator.add(Conv2D(16, 3, padding='same'))\n",
    "discriminator.add(BatchNormalization(momentum=0.9))\n",
    "discriminator.add(LeakyReLU(alpha=0.2))\n",
    "discriminator.add(AveragePooling2D(pool_size=5, strides=2, padding='same'))\n",
    "                  \n",
    "discriminator.add(Conv2D(32, 1, padding='valid'))\n",
    "discriminator.add(BatchNormalization(momentum=0.9))\n",
    "discriminator.add(AveragePooling2D(pool_size=5, strides=2, padding='same'))\n",
    "\n",
    "discriminator.add(Conv2D(64, 1, padding='valid'))\n",
    "discriminator.add(BatchNormalization(momentum=0.9))\n",
    "discriminator.add(AveragePooling2D(pool_size=5, strides=2, padding='same'))\n",
    "\n",
    "discriminator.add(Conv2D(128, 3, padding='same'))\n",
    "discriminator.add(BatchNormalization(momentum=0.9))\n",
    "discriminator.add(LeakyReLU(alpha=0.2))\n",
    "discriminator.add(AveragePooling2D(pool_size=5, strides=2, padding='same'))\n",
    "\n",
    "discriminator.add(SpatialPyramidPooling([1, 2, 4]))\n",
    "\n",
    "discriminator.add(Dense(128))\n",
    "\n",
    "discriminator.add(Dense(2, activation='tanh'))\n",
    "\n",
    "discriminator.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_lfw_people\n",
    "lfw_people = fetch_lfw_people(color=True, resize=1.0, slice_=(slice(0, 250), slice(0, 250)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(13233, 3, 250, 250)\n"
     ]
    }
   ],
   "source": [
    "images_rgb = lfw_people.images\n",
    "images_rgb = np.moveaxis(images_rgb, -1, 1)\n",
    "print(images_rgb.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rgb2ycc(img_rgb):\n",
    "    \"\"\"\n",
    "    Takes as input a RGB image and convert it to Y Cb Cr space. The shape is channels first.\n",
    "    \"\"\"\n",
    "    output = np.zeros(np.shape(img_rgb))\n",
    "    output[0, :, :] = 0.299 * img_rgb[0, :, :] + 0.587 * img_rgb[1, :, :] + 0.114 * img_rgb[2, :, :]\n",
    "    output[1, :, :] = -0.1687 * img_rgb[0, :, :] - 0.3313 * img_rgb[1, :, :] + 0.5 * img_rgb[2, :, :] + 128\n",
    "    output[2, :, :] = 0.5 * img_rgb[0, :, :] - 0.4187 * img_rgb[1, :, :] + 0.0813 * img_rgb[2, :, :] + 128\n",
    "\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "images_ycc = np.zeros(images_rgb.shape)\n",
    "for k in range(images_rgb.shape[0]):\n",
    "    images_ycc[k, :, :, :] = rgb2ycc(images_rgb[k, :, :, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = (images_ycc.astype(np.float32) - 127.5) / 127.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "cover_idx = np.random.randint(0, X_train.shape[0], batch_size)\n",
    "secret_idx = np.random.randint(0, X_train.shape[0], batch_size)\n",
    "cover_imgs = X_train[cover_idx]\n",
    "cover_imgs_Y = cover_\n",
    "secret_imgs = X_train[secret_idx]\n",
    "\n",
    "enc_input = np.concatenate((cover_imgs, secret_imgs), axis=1)\n",
    "# enc_imgs = self.encoder.predict(enc_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rgb2gray(img_rgb):\n",
    "    \"\"\"\n",
    "    Transform a RGB image into a grayscale one using weighted method. Shape: channels first.\n",
    "    \"\"\"\n",
    "    output = np.zeros((1, img_rgb.shape[1], img_rgb.shape[2]))\n",
    "    output[0, :, :] = 0.3 * img_rgb[0, :, :] + 0.59 * img_rgb[1, :, :] + 0.11 * img_rgb[2, :, :]\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "images_gray = np.zeros((images_rgb.shape[0], 1, images_rgb.shape[2], images_rgb.shape[3]))\n",
    "for k in range(images_rgb.shape[0]):\n",
    "    images_gray[k, 0, :, :] = rgb2gray(images_rgb[k, :, :, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.10833984  0.95407497  0.78329048  0.71951861]\n",
      " [ 0.10182542  0.49493423  0.45324552  0.64322044]\n",
      " [ 0.88850775  0.37323487  0.54702865  0.90627754]\n",
      " [ 0.87230472  0.25230752  0.51192716  0.24997722]]\n",
      "[[ 0.          0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.10833984  0.95407497  0.78329048\n",
      "   0.71951861  0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.10182542  0.49493423  0.45324552\n",
      "   0.64322044  0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.88850775  0.37323487  0.54702865\n",
      "   0.90627754  0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.87230472  0.25230752  0.51192716\n",
      "   0.24997722  0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.        ]]\n"
     ]
    }
   ],
   "source": [
    "A = np.random.rand(3,4,4,4)\n",
    "print(A[0,0,:,:])\n",
    "B = np.pad(A, ((0,0), (0,0), (3,3), (3,3)), 'constant')\n",
    "print(B[0,0,:,:])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
